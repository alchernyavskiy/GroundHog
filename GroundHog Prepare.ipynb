{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get splits for BART training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/threads_with_metas_3ut_aug_full.pkl', 'rb') as f:\n",
    "    threads = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_token = '</s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_set = set()\n",
    "speakers_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discourse_tokens(discourse_list):\n",
    "    return [f'<u{discourse_list[1]+1}>', f'<to:u{discourse_list[0]+1}>', f'<{discourse_list[2]}>']\n",
    "\n",
    "\n",
    "def get_aug_value(ut, speaker='<s1>'):\n",
    "    return ' '.join([speaker] + get_discourse_tokens(ut['discourse']) + ['<' + ut['sentiment'][0] + '>', ut['text']])\n",
    "\n",
    "\n",
    "def preproc_text(text, utt_set, speakers_set):\n",
    "    utt_set |= set(re.findall(r'<u\\d+>', text))\n",
    "    speakers_set |= set(re.findall(r'<s\\d+>', text))\n",
    "    if type(text) == str:\n",
    "        res = re.sub(r'\\s+', ' ', str(text))\n",
    "        if len(res.strip()) == 0:\n",
    "            return 'unk'\n",
    "        return res.strip()\n",
    "    return 'unk'\n",
    "\n",
    "\n",
    "def get_dialogue_instances(threads, utt_set, speakers_set):\n",
    "    utter_covered = set() # кажду реплику генерим только один раз\n",
    "    \n",
    "    result = []\n",
    "    for thr in tqdm(threads):\n",
    "        speakers = {}\n",
    "        \n",
    "        for i, ut in enumerate(thr['dialogue']):\n",
    "            speaker = ut['speaker']\n",
    "            if speaker not in speakers:\n",
    "                speakers[speaker] = '<s' + str(len(speakers) + 1) + '>'\n",
    "            \n",
    "            if i >= 2:\n",
    "                if thr['id'] + '_' + ut['id'] not in utter_covered:\n",
    "                    utter_covered.add(thr['id'] + '_' + ut['id'])\n",
    "                    \n",
    "                    utter_dict = {\n",
    "                        'thread_id': thr['id'],\n",
    "                        'id': thr['id'] + '_' + ut['id'],\n",
    "                        'history': f' {sep_token} '.join([speakers[ut_his['speaker']] + ' ' + ut_his['text'] for\n",
    "                                                         ut_his in thr['dialogue'][:i]] + [speakers[ut['speaker']]]),\n",
    "                        'history_aug': f' {sep_token} '.join([get_aug_value(ut_his, speakers[ut_his['speaker']]) for\n",
    "                                                              ut_his in thr['dialogue'][:i]] +\n",
    "                                                             [' '.join(get_aug_value(ut, speakers[ut['speaker']]).split()[:3])]),\n",
    "                        'history_amr': f' {sep_token} '.join([ut_his['amr'] for ut_his in thr['dialogue'][:i]]),\n",
    "                        'history_discourse': f' {sep_token} '.join([' '.join(get_discourse_tokens(ut_his['discourse'])) for\n",
    "                                                             ut_his in thr['dialogue'][:i]]),\n",
    "                        'addr_amr': thr['dialogue'][i-1]['amr'],\n",
    "                        'response': ut['text'],\n",
    "                        'response_aug': ' '.join(get_aug_value(ut, speakers[ut['speaker']]).split()[3:]),\n",
    "                        'grounding': thr['grounding'],\n",
    "                        'title': thr['meta']['title'],\n",
    "                    }\n",
    "                    \n",
    "                    for k in utter_dict:\n",
    "                        try:\n",
    "                            utter_dict[k] = preproc_text(utter_dict[k], utt_set, speakers_set)\n",
    "                        except:\n",
    "                            utter_dict[k] = 'unk'\n",
    "                    \n",
    "                    if len(utter_dict['response']) > 3:\n",
    "                        result.append(utter_dict)\n",
    "                    \n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39803/39803 [00:24<00:00, 1601.39it/s]\n"
     ]
    }
   ],
   "source": [
    "dialogue_df = get_dialogue_instances(threads, utt_set, speakers_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74069, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split by thread ids\n",
    "train_threads, val_threads = train_test_split(list(dialogue_df['thread_id'].unique()), test_size=0.1, random_state=575)\n",
    "train_df = dialogue_df[dialogue_df.thread_id.isin(train_threads)]\n",
    "val_df = dialogue_df[dialogue_df.thread_id.isin(val_threads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67597, 11), (6472, 11))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('bart_input/train_reddit_dial_df.csv', sep='\\t', index=False)\n",
    "val_df.to_csv('bart_input/val_reddit_dial_df.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "disco_rels = ['<negativereaction>',\n",
    "             '<other>',\n",
    "             '<appreciation>',\n",
    "             '<unk>',\n",
    "             '<elaboration>',\n",
    "             '<answer>',\n",
    "             '<question>',\n",
    "             '<humor>',\n",
    "             '<announcement>',\n",
    "             '<agreement>',\n",
    "             '<disagreement>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens_list = sorted(list(utt_set)) +\\\n",
    "                      sorted([u.replace('<', '<to:') for u in list(utt_set)]) +\\\n",
    "                      sorted(list(speakers_set)) +\\\n",
    "                      ['<Negative>', '<Neutral>', '<Positive>'] +\\\n",
    "                      disco_rels + ['<init>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(special_tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens_dict = {'additional_special_tokens': special_tokens_list,\n",
    "                         'bos_token': '<s>',\n",
    "                         'eos_token': '</s>',\n",
    "                         'unk_token': '<unk>',\n",
    "                         'sep_token': '</s>',\n",
    "                         'pad_token': '<pad>',\n",
    "                         'cls_token': '<s>',\n",
    "                         'mask_token': '<mask>'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bart_input/special_tokens_map_reddit_dial.pkl', 'wb') as f:\n",
    "    pickle.dump(special_tokens_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate source & target lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_name_or_path = \"facebook/bart-base\"\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name_or_path)\n",
    "model =  BartForConditionalGeneration.from_pretrained(model_name_or_path).to(device) # to check load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bart_input/special_tokens_map_reddit_dial.pkl', 'rb') as f:\n",
    "    special_tokens_dict = pickle.load(f)\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 123/68445 [00:00<02:35, 438.55it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 68445/68445 [01:28<00:00, 773.69it/s] \n",
      "100%|██████████| 68445/68445 [01:32<00:00, 740.33it/s] \n",
      "100%|██████████| 68445/68445 [02:02<00:00, 557.01it/s] \n",
      "100%|██████████| 68445/68445 [00:12<00:00, 5403.48it/s]\n",
      "100%|██████████| 68445/68445 [00:38<00:00, 1800.54it/s]\n",
      "100%|██████████| 68445/68445 [00:26<00:00, 2631.42it/s]\n",
      "100%|██████████| 68445/68445 [00:27<00:00, 2517.32it/s]\n",
      "100%|██████████| 68445/68445 [00:37<00:00, 1830.03it/s] \n",
      "100%|██████████| 68445/68445 [00:19<00:00, 3600.38it/s]\n"
     ]
    }
   ],
   "source": [
    "lens = {}\n",
    "for column in train_df:\n",
    "    if 'id' not in column:\n",
    "        num_tokens_text = []\n",
    "        for record in tqdm(train_df[column].values):\n",
    "            num_tokens_text.append(len(tokenizer.encode(record)))\n",
    "        lens[column] = (np.mean(num_tokens_text), np.median(num_tokens_text), np.quantile(num_tokens_text, 0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': (193.21510702023522, 123.0, 570.0),\n",
       " 'history_aug': (210.1300314120827, 139.0, 597.0),\n",
       " 'history_amr': (374.19500328731095, 258.0, 1016.0),\n",
       " 'history_discourse': (15.91492439184747, 13.0, 33.0),\n",
       " 'addr_amr': (99.22618160566878, 67.0, 271.0),\n",
       " 'response': (42.63747534516765, 25.0, 134.0),\n",
       " 'response_aug': (44.620147563737305, 27.0, 136.0),\n",
       " 'grounding': (86.53854920008766, 2.0, 841.0),\n",
       " 'title': (30.278325662941047, 26.0, 63.0)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
