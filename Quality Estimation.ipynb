{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from rouge import Rouge\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bart_input/special_tokens_map_reddit_dial.pkl', 'rb') as f:\n",
    "    special_tokens_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_tokens(s):\n",
    "    for t in special_tokens_dict['additional_special_tokens']:\n",
    "        s = s.replace(t, '')\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(preds):\n",
    "    y_true = np.array([p[0] for p in preds])\n",
    "    y_pred = np.array([p[1] for p in preds])\n",
    "    return np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_full = pd.read_csv(\"bart_input/val_reddit_dial_df_multi_extented_filt.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_from_fn(x):\n",
    "    if 'base' in x:\n",
    "        return 'Base model'\n",
    "    if 'history-title_' in x:\n",
    "        return 'GroundHog: history, title'\n",
    "    if 'history#title#grounding' in x:\n",
    "        return '+grounding'\n",
    "    if 'to:response_disco' in x:\n",
    "        return '+discourse planning'\n",
    "    if 'to:response_aug' in x:\n",
    "        return '+sentiment&discourse planning'\n",
    "    if 'history_aug#' in x:\n",
    "        return '+sentiment'\n",
    "    if 'from:history_aug_disco' in x and 'amr' not in x:\n",
    "        return '+discourse'\n",
    "    return '+AMR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_paths = [\n",
    " 'base_bart_bs8_4ep_lr3e-05__from:history-title-grounding___to:response_nbeams1.pkl',\n",
    " 'multiencoder_bart_v2_bs8_4ep_lr3e-05_enclen256__from:history#title-history-title___to:response.pkl',\n",
    " 'multiencoder_bart_v2_bs8_4ep_lr3e-05_enclen256__from:history#title#grounding-history-title-grounding___to:response.pkl',\n",
    " 'multiencoder_bart_v2_bs8_4ep_lr3e-05_enclen256__from:history_aug_disco#title#grounding-history_aug_disco-title-grounding-history_discourse___to:response.pkl',\n",
    " 'multiencoder_bart_v2_bs8_4ep_lr3e-05_enclen256__from:history_aug_disco#title#grounding-history_aug_disco-title-grounding-history_discourse-history_amr-addr_amr___to:response.pkl',\n",
    " 'multiencoder_bart_v2_bs8_4ep_lr3e-05_enclen256__from:history_aug#title#grounding-history_aug-title-grounding-history_discourse-history_amr-addr_amr___to:response.pkl',\n",
    " 'multiencoder_bart_v2_bs8_4ep_lr3e-05_enclen256__from:history_aug#title#grounding-history_aug-title-grounding-history_discourse-history_amr-addr_amr___to:response_disco.pkl',\n",
    " 'multiencoder_bart_v2_bs8_4ep_lr3e-05_enclen256__from:history_aug#title#grounding-history_aug-title-grounding-history_discourse-history_amr-addr_amr___to:response_aug.pkl',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_bart_bs8_4ep_lr3e-05__from:history-title-grounding___to:response_nbeams1.pkl\n",
      "Base model\n",
      "\n",
      "ROUGE-1: 17.71\n",
      "ROUGE-2: 3.69\n",
      "ROUGE-L: 15.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aschernyavskiy/anaconda3/lib/python3.6/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/aschernyavskiy/anaconda3/lib/python3.6/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/aschernyavskiy/anaconda3/lib/python3.6/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 17.2\n",
      "BLEU-2: 2.86\n",
      "BLEU-3: 2.44\n",
      "BLEU-4: 2.37\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "multiencoder_bart_v2_bs8_4ep_lr3e-05_enclen256__from:history#title-history-title___to:response.pkl\n",
      "GroundHog: history, title\n",
      "\n",
      "ROUGE-1: 17.79\n",
      "ROUGE-2: 3.71\n",
      "ROUGE-L: 16.05\n",
      "BLEU-1: 16.99\n",
      "BLEU-2: 2.88\n",
      "BLEU-3: 2.49\n",
      "BLEU-4: 2.44\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "multiencoder_bart_v2_bs8_4ep_lr3e-05_enclen256__from:history#title#grounding-history-title-grounding___to:response.pkl\n",
      "+grounding\n",
      "\n",
      "ROUGE-1: 17.86\n",
      "ROUGE-2: 3.85\n",
      "ROUGE-L: 16.08\n",
      "BLEU-1: 17.32\n",
      "BLEU-2: 3.0\n",
      "BLEU-3: 2.6\n",
      "BLEU-4: 2.54\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "multiencoder_bart_v2_bs8_4ep_lr3e-05_enclen256__from:history_aug_disco#title#grounding-history_aug_disco-title-grounding-history_discourse___to:response.pkl\n",
      "+discourse\n",
      "\n",
      "ROUGE-1: 17.88\n",
      "ROUGE-2: 3.87\n",
      "ROUGE-L: 16.09\n",
      "BLEU-1: 17.15\n",
      "BLEU-2: 3.04\n",
      "BLEU-3: 2.63\n",
      "BLEU-4: 2.57\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "multiencoder_bart_v2_bs8_4ep_lr3e-05_enclen256__from:history_aug_disco#title#grounding-history_aug_disco-title-grounding-history_discourse-history_amr-addr_amr___to:response.pkl\n",
      "+discourse\n",
      "\n",
      "ROUGE-1: 17.88\n",
      "ROUGE-2: 3.8\n",
      "ROUGE-L: 16.17\n",
      "BLEU-1: 17.26\n",
      "BLEU-2: 2.94\n",
      "BLEU-3: 2.54\n",
      "BLEU-4: 2.48\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "multiencoder_bart_v2_bs8_4ep_lr3e-05_enclen256__from:history_aug#title#grounding-history_aug-title-grounding-history_discourse-history_amr-addr_amr___to:response.pkl\n",
      "+sentiment\n",
      "\n",
      "ROUGE-1: 17.91\n",
      "ROUGE-2: 3.93\n",
      "ROUGE-L: 16.19\n",
      "BLEU-1: 17.25\n",
      "BLEU-2: 3.09\n",
      "BLEU-3: 2.69\n",
      "BLEU-4: 2.64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "multiencoder_bart_v2_bs8_4ep_lr3e-05_enclen256__from:history_aug#title#grounding-history_aug-title-grounding-history_discourse-history_amr-addr_amr___to:response_disco.pkl\n",
      "+discourse planning\n",
      "\n",
      "ROUGE-1: 17.82\n",
      "ROUGE-2: 3.74\n",
      "ROUGE-L: 16.11\n",
      "BLEU-1: 17.14\n",
      "BLEU-2: 2.91\n",
      "BLEU-3: 2.52\n",
      "BLEU-4: 2.47\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "multiencoder_bart_v2_bs8_4ep_lr3e-05_enclen256__from:history_aug#title#grounding-history_aug-title-grounding-history_discourse-history_amr-addr_amr___to:response_aug.pkl\n",
      "+sentiment&discourse planning\n",
      "Accuracy discourse: 0.553\n",
      "Accuracy sentiment: 0.419\n",
      "\n",
      "ROUGE-1: 17.89\n",
      "ROUGE-2: 3.83\n",
      "ROUGE-L: 16.18\n",
      "BLEU-1: 17.35\n",
      "BLEU-2: 3.05\n",
      "BLEU-3: 2.64\n",
      "BLEU-4: 2.58\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = test_data_full\n",
    "for res_path in results_paths:\n",
    "    if 'base' in res_path or ('enclen256' in res_path and '_v2_' in res_path) and \\\n",
    "            ('10ep' not in res_path and 'multiencoder_bart_v2_bs8_7ep' not in res_path):\n",
    "        #try:\n",
    "        print(res_path)\n",
    "        print(info_from_fn(res_path))\n",
    "        with open('predictions/' + res_path, 'rb') as f:\n",
    "            preds = pickle.load(f)\n",
    "            preds = np.array(preds)\n",
    "            \n",
    "        target_col = res_path.split('__')[-1][4:].replace('.pkl', '').replace('_nbeams1', '')\n",
    "        y_test = test_data[target_col].values\n",
    "            \n",
    "        if '_aug' in target_col:\n",
    "            relations = []\n",
    "            sentiment = []\n",
    "            for i in range(len(preds)):\n",
    "                if preds[i] != '' and len(preds[i].split()) > 2:\n",
    "                    pred_rel, pred_sentim, _ = preds[i].split(' ', 2)\n",
    "                    rel, sentim, _ = y_test[i].split(' ', 2)\n",
    "                    relations.append([rel, pred_rel])\n",
    "                    sentiment.append([sentim, pred_sentim])\n",
    "\n",
    "            print('Accuracy discourse:', round(calc_accuracy(relations), 3))\n",
    "            print('Accuracy sentiment:', round(calc_accuracy(sentiment), 3))\n",
    "\n",
    "        rouge = Rouge()\n",
    "        hyps, refs = [], []\n",
    "        notcalc = 0\n",
    "        for i in range(len(preds)):\n",
    "            pred_text = remove_special_tokens(preds[i])\n",
    "            gt_text = remove_special_tokens(y_test[i])\n",
    "            #if len(pred_text.split(' ', 2)) > 1 and len(gt_text.split(' ', 2)) > 1:\n",
    "            hyps.append(pred_text)\n",
    "            refs.append(gt_text)\n",
    "\n",
    "            #if len(pred_text.split(' ', 2)) <= 1 and len(gt_text.split(' ', 2)) > 1:\n",
    "            #    notcalc += 1\n",
    "        #print('\\nShort preds:', notcalc)\n",
    "\n",
    "        gen_ref = zip(hyps, refs)\n",
    "        gen_ref = [_ for _ in gen_ref if not all(j in string.punctuation for j in _[1]) and not all(j in string.punctuation for j in _[0])]\n",
    "        gens, refs  = zip(*gen_ref)\n",
    "\n",
    "        rouge_res = rouge.get_scores(gens, refs, avg=True, ignore_empty=False)\n",
    "        print()\n",
    "        print('ROUGE-1:', round(100 * rouge_res['rouge-1']['f'], 2))\n",
    "        print('ROUGE-2:', round(100 * rouge_res['rouge-2']['f'], 2))\n",
    "        print('ROUGE-L:', round(100 * rouge_res['rouge-l']['f'], 2))\n",
    "\n",
    "        for j in range(1, 5):\n",
    "            weights=[0,0,0,0]\n",
    "            for k in range(j):\n",
    "                weights[k] = 1\n",
    "            mean_bleu = 0\n",
    "            for gen, ref in zip(gens, refs):\n",
    "                mean_bleu += sentence_bleu([word_tokenize(ref)], word_tokenize(gen), weights=weights)\n",
    "            mean_bleu /= len(gens)\n",
    "            print(f'BLEU-{j}:', round(100 * mean_bleu, 2)) \n",
    "\n",
    "        print('\\n' + '-'*50 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_size = int(15716 / 0.25 * 0.1) # size for real proportions\n",
    "test_data_short = pd.read_csv(\"bart_input/val_reddit_dial_df_multi_extented_short.csv\", sep='\\t').head(short_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data_full\n",
    "for res_path in results_paths:\n",
    "    if 'base' in res_path or ('enclen256' in res_path and '_v2_' in res_path) and \\\n",
    "            ('10ep' not in res_path and 'multiencoder_bart_v2_bs8_7ep' not in res_path):\n",
    "        #try:\n",
    "        print(res_path)\n",
    "        print(info_from_fn(res_path))\n",
    "        with open('predictions/' + res_path, 'rb') as f:\n",
    "            preds = pickle.load(f)\n",
    "            preds = np.array(preds)\n",
    "            \n",
    "        with open('predictions/' + res_path.replace('.pkl', 'short.pkl').replace('nbeams1short.pkl', 'short.pkl'), 'rb') as f:\n",
    "            preds_short = pickle.load(f)\n",
    "            preds = list(preds) + list(preds_short[:short_size])\n",
    "            \n",
    "        target_col = res_path.split('__')[-1][4:].replace('.pkl', '').replace('_nbeams1', '')\n",
    "        y_test = list(test_data_full['response'].values) + list(test_data_short['response'].values)\n",
    "            \n",
    "        if '_aug' in target_col:\n",
    "            relations = []\n",
    "            sentiment = []\n",
    "            for i in range(len(preds)):\n",
    "                if preds[i] != '' and len(preds[i].split()) > 2:\n",
    "                    pred_rel, pred_sentim, _ = preds[i].split(' ', 2)\n",
    "                    rel, sentim, _ = y_test[i].split(' ', 2)\n",
    "                    relations.append([rel, pred_rel])\n",
    "                    sentiment.append([sentim, pred_sentim])\n",
    "\n",
    "            print('Accuracy discourse:', round(calc_accuracy(relations), 3))\n",
    "            print('Accuracy sentiment:', round(calc_accuracy(sentiment), 3))\n",
    "\n",
    "        rouge = Rouge()\n",
    "        hyps, refs = [], []\n",
    "        notcalc = 0\n",
    "        for i in range(len(preds)):\n",
    "            pred_text = remove_special_tokens(preds[i])\n",
    "            gt_text = remove_special_tokens(y_test[i])\n",
    "            #if len(pred_text.split(' ', 2)) > 1 and len(gt_text.split(' ', 2)) > 1:\n",
    "            hyps.append(pred_text)\n",
    "            refs.append(gt_text)\n",
    "\n",
    "            #if len(pred_text.split(' ', 2)) <= 1 and len(gt_text.split(' ', 2)) > 1:\n",
    "            #    notcalc += 1\n",
    "        #print('\\nShort preds:', notcalc)\n",
    "\n",
    "        gen_ref = zip(hyps, refs)\n",
    "        gen_ref = [_ for _ in gen_ref if not all(j in string.punctuation for j in _[1]) and not all(j in string.punctuation for j in _[0])]\n",
    "        gens, refs  = zip(*gen_ref)\n",
    "\n",
    "        rouge_res = rouge.get_scores(gens, refs, avg=True, ignore_empty=False)\n",
    "        print()\n",
    "        print('ROUGE-1:', round(100 * rouge_res['rouge-1']['f'], 2))\n",
    "        print('ROUGE-2:', round(100 * rouge_res['rouge-2']['f'], 2))\n",
    "        print('ROUGE-L:', round(100 * rouge_res['rouge-l']['f'], 2))\n",
    "\n",
    "        for j in range(1, 5):\n",
    "            weights=[0,0,0,0]\n",
    "            for k in range(j):\n",
    "                weights[k] = 1\n",
    "            mean_bleu = 0\n",
    "            for gen, ref in zip(gens, refs):\n",
    "                mean_bleu += sentence_bleu([word_tokenize(ref)], word_tokenize(gen), weights=weights)\n",
    "            mean_bleu /= len(gens)\n",
    "            print(f'BLEU-{j}:', round(100 * mean_bleu, 2)) \n",
    "\n",
    "        print('\\n' + '-'*50 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
